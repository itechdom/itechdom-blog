# Definition
### Statistics + ML
### Statistical Learning
### A branch of Artificial Intellegence
### Closely related to statistics
### ML VS Data mining
Machine learning and data mining often employ the same methods and overlap significantly. They can be roughly distinguished as follows:

*   Machine learning focuses on prediction, based on _known_ properties learned from the training data.
*   [Data mining](https://en.wikipedia.org/wiki/Data_mining "Data mining") focuses on the [discovery](https://en.wikipedia.org/wiki/Discovery_(observation) "Discovery (observation)") of (previously) _unknown_ properties in the data. This is the analysis step of [Knowledge Discovery](https://en.wikipedia.org/wiki/Knowledge_discovery "Knowledge discovery") in Databases.
# Resources
### List of machine learning algorithms
### https://en.wikipedia.org/wiki/Machine_learning
# History
### Instead of hard if, then rules
### We have statistical models than can predict things more accurately
# Concept
### Data sets
### Model
### Supervised learning
### Unsupervised Learning
### Concern with reducing the loss within a model
# Approaches
## Approaches[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=6 "Edit section: Approaches")]

Main article: [List of machine learning algorithms](https://en.wikipedia.org/wiki/List_of_machine_learning_algorithms "List of machine learning algorithms")

### Decision tree learning[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=7 "Edit section: Decision tree learning")]

Main article: [Decision tree learning](https://en.wikipedia.org/wiki/Decision_tree_learning "Decision tree learning")

Decision tree learning uses a [decision tree](https://en.wikipedia.org/wiki/Decision_tree "Decision tree") as a [predictive model](https://en.wikipedia.org/wiki/Predictive_modelling "Predictive modelling"), which maps observations about an item to conclusions about the item's target value.

### Association rule learning[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=8 "Edit section: Association rule learning")]

Main article: [Association rule learning](https://en.wikipedia.org/wiki/Association_rule_learning "Association rule learning")

Association rule learning is a method for discovering interesting relations between variables in large databases.

### Artificial neural networks[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=9 "Edit section: Artificial neural networks")]

Main article: [Artificial neural network](https://en.wikipedia.org/wiki/Artificial_neural_network "Artificial neural network")

An [artificial neural network](https://en.wikipedia.org/wiki/Artificial_neural_network "Artificial neural network") (ANN) learning algorithm, usually called "neural network" (NN), is a learning algorithm that is inspired by the structure and functional aspects of [biological neural networks](https://en.wikipedia.org/wiki/Biological_neural_networks "Biological neural networks"). Computations are structured in terms of an interconnected group of [artificial neurons](https://en.wikipedia.org/wiki/Artificial_neuron "Artificial neuron"), processing information using a [connectionist](https://en.wikipedia.org/wiki/Connectionism "Connectionism") approach to [computation](https://en.wikipedia.org/wiki/Computation "Computation"). Modern neural networks are[non-linear](https://en.wikipedia.org/wiki/Non-linear "Non-linear") [statistical](https://en.wikipedia.org/wiki/Statistical "Statistical") [data modeling](https://en.wikipedia.org/wiki/Data_modeling "Data modeling") tools. They are usually used to model complex relationships between inputs and outputs, to [find patterns](https://en.wikipedia.org/wiki/Pattern_recognition "Pattern recognition") in data, or to capture the statistical structure in an unknown [joint probability distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution "Joint probability distribution") between observed variables.

### Inductive logic programming[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=10 "Edit section: Inductive logic programming")]

Main article: [Inductive logic programming](https://en.wikipedia.org/wiki/Inductive_logic_programming "Inductive logic programming")

Inductive logic programming (ILP) is an approach to rule learning using [logic programming](https://en.wikipedia.org/wiki/Logic_programming "Logic programming") as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that [entails](https://en.wikipedia.org/wiki/Entailment "Entailment") all positive and no negative examples. [Inductive programming](https://en.wikipedia.org/wiki/Inductive_programming "Inductive programming") is a related field that considers any kind of programming languages for representing hypotheses (and not only logic programming), such as functional programs.

### Support vector machines[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=11 "Edit section: Support vector machines")]

Main article: [Support vector machines](https://en.wikipedia.org/wiki/Support_vector_machines "Support vector machines")

Support vector machines (SVMs) are a set of related [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning "Supervised learning") methods used for [classification](https://en.wikipedia.org/wiki/Statistical_classification "Statistical classification") and [regression](https://en.wikipedia.org/wiki/Regression_analysis "Regression analysis"). Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category or the other.

### Clustering[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=12 "Edit section: Clustering")]

Main article: [Cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis "Cluster analysis")

Cluster analysis is the assignment of a set of observations into subsets (called _clusters_) so that observations within the same cluster are similar according to some predesignated criterion or criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some _similarity metric_ and evaluated for example by _internal compactness_ (similarity between members of the same cluster) and _separation_ between different clusters. Other methods are based on _estimated density_ and _graph connectivity_. Clustering is a method of [unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning "Unsupervised learning"), and a common technique for [statistical](https://en.wikipedia.org/wiki/Statistics "Statistics") [data analysis](https://en.wikipedia.org/wiki/Data_analysis "Data analysis").

### Bayesian networks[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=13 "Edit section: Bayesian networks")]

Main article: [Bayesian network](https://en.wikipedia.org/wiki/Bayesian_network "Bayesian network")

A Bayesian network, belief network or directed acyclic graphical model is a [probabilistic graphical model](https://en.wikipedia.org/wiki/Graphical_model "Graphical model") that represents a set of [random variables](https://en.wikipedia.org/wiki/Random_variables "Random variables") and their [conditional independencies](https://en.wikipedia.org/wiki/Conditional_independence "Conditional independence") via a[directed acyclic graph](https://en.wikipedia.org/wiki/Directed_acyclic_graph "Directed acyclic graph") (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform [inference](https://en.wikipedia.org/wiki/Inference "Inference") and learning.

### Reinforcement learning[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=14 "Edit section: Reinforcement learning")]

Main article: [Reinforcement learning](https://en.wikipedia.org/wiki/Reinforcement_learning "Reinforcement learning")

Reinforcement learning is concerned with how an _agent_ ought to take _actions_ in an _environment_ so as to maximize some notion of long-term _reward_. Reinforcement learning algorithms attempt to find a _policy_ that maps _states_ of the world to the actions the agent ought to take in those states. Reinforcement learning differs from the [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning "Supervised learning") problem in that correct input/output pairs are never presented, nor sub-optimal actions explicitly corrected.

### Representation learning[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=15 "Edit section: Representation learning")]

Main article: [Representation learning](https://en.wikipedia.org/wiki/Representation_learning "Representation learning")

Several learning algorithms, mostly [unsupervised learning](https://en.wikipedia.org/wiki/Unsupervised_learning "Unsupervised learning") algorithms, aim at discovering better representations of the inputs provided during training. Classical examples include [principal components analysis](https://en.wikipedia.org/wiki/Principal_components_analysis "Principal components analysis") and [cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis "Cluster analysis"). Representation learning algorithms often attempt to preserve the information in their input but transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions, allowing to reconstruct the inputs coming from the unknown data generating distribution, while not being necessarily faithful for configurations that are implausible under that distribution.

[Manifold learning](https://en.wikipedia.org/wiki/Manifold_learning "Manifold learning") algorithms attempt to do so under the constraint that the learned representation is low-dimensional. [Sparse coding](https://en.wikipedia.org/wiki/Sparse_coding "Sparse coding") algorithms attempt to do so under the constraint that the learned representation is sparse (has many zeros). [Multilinear subspace learning](https://en.wikipedia.org/wiki/Multilinear_subspace_learning "Multilinear subspace learning") algorithms aim to learn low-dimensional representations directly from [tensor](https://en.wikipedia.org/wiki/Tensor "Tensor") representations for multidimensional data, without reshaping them into (high-dimensional) vectors.[[17]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-17) [Deep learning](https://en.wikipedia.org/wiki/Deep_learning "Deep learning") algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.[[18]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-18)

### Similarity and metric learning[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=16 "Edit section: Similarity and metric learning")]

Main article: [Similarity learning](https://en.wikipedia.org/wiki/Similarity_learning "Similarity learning")

In this problem, the learning machine is given pairs of examples that are considered similar and pairs of less similar objects. It then needs to learn a similarity function (or a distance metric function) that can predict if new objects are similar. It is sometimes used in [Recommendation systems](https://en.wikipedia.org/wiki/Recommendation_systems "Recommendation systems").

### Sparse dictionary learning[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=17 "Edit section: Sparse dictionary learning")]

Main article: [Sparse dictionary learning](https://en.wikipedia.org/wiki/Sparse_dictionary_learning "Sparse dictionary learning")

In this method, a datum is represented as a linear combination of basis functions, and the coefficients are assumed to be sparse. Let _x_ be a _d_-dimensional datum, _D_ be a _d_ by _n_ matrix, where each column of _D_ represents a basis function. _r_ is the coefficient to represent _x_ using _D_. Mathematically, sparse dictionary learning means solving ![x \approx D r](https://upload.wikimedia.org/math/c/5/a/c5a06d5e6226b8d57b76ecfc1677896a.png) where _r_ is sparse. Generally speaking, _n_ is assumed to be larger than _d_ to allow the freedom for a sparse representation.

Learning a dictionary along with sparse representations is [strongly NP-hard](https://en.wikipedia.org/wiki/Strongly_NP-hard "Strongly NP-hard") and also difficult to solve approximately.[[19]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-19) A popular heuristic method for sparse dictionary learning is [K-SVD](https://en.wikipedia.org/wiki/K-SVD "K-SVD").

Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine which classes a previously unseen datum belongs to. Suppose a dictionary for each class has already been built. Then a new datum is associated with the class such that it's best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[[20]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-20)

### Genetic algorithms[[edit](https://en.wikipedia.org/w/index.php?title=Machine_learning&action=edit&section=18 "Edit section: Genetic algorithms")]

Main article: [Genetic algorithm](https://en.wikipedia.org/wiki/Genetic_algorithm "Genetic algorithm")

A genetic algorithm (GA) is a [search](https://en.wikipedia.org/wiki/Search_algorithm "Search algorithm") [heuristic](https://en.wikipedia.org/wiki/Heuristic_(computer_science) "Heuristic (computer science)") that mimics the process of [natural selection](https://en.wikipedia.org/wiki/Natural_selection "Natural selection"), and uses methods such as [mutation](https://en.wikipedia.org/wiki/Mutation_(genetic_algorithm) "Mutation (genetic algorithm)") and [crossover](https://en.wikipedia.org/wiki/Crossover_(genetic_algorithm) "Crossover (genetic algorithm)") to generate new [genotype](https://en.wikipedia.org/wiki/Chromosome_(genetic_algorithm) "Chromosome (genetic algorithm)") in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms found some uses in the 1980s and 1990s.[[21]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-21)[[22]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-22) Vice versa, machine learning techniques have been used to improve the performance of genetic and [evolutionary algorithms](https://en.wikipedia.org/wiki/Evolutionary_algorithm "Evolutionary algorithm").[[23]](https://en.wikipedia.org/wiki/Machine_learning#cite_note-23)
